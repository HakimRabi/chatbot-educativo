# ===== IMPORTS =====
from fastapi import FastAPI, Request, BackgroundTasks
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse, StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
import logging
import asyncio
from concurrent.futures import ThreadPoolExecutor
import time
import json
import uuid
from pydantic import BaseModel
from datetime import datetime

# ===== IMPORTS PARA ARQUITECTURA ASINCR√ìNICA =====
try:
    from celery import Celery
    from celery.result import AsyncResult
    CELERY_AVAILABLE = True
    logger = logging.getLogger("chatbot_app")
    logger.info("üîß Celery disponible - arquitectura asincr√≥nica habilitada")
except ImportError:
    CELERY_AVAILABLE = False
    logger = logging.getLogger("chatbot_app")
    logger.warning("‚ö†Ô∏è Celery no disponible - usando modo sincr√≥nico")
import uuid
from pydantic import BaseModel
from datetime import datetime

# Sistema de m√©tricas - FASE 1
try:
    from metrics import (
        start_request_tracking, 
        end_request_tracking, 
        record_model_switch,
        get_metrics_summary,
        get_bottleneck_analysis
    )
    METRICS_ENABLED = True
    logger = logging.getLogger("chatbot_app")
    logger.info("üîç Sistema de m√©tricas habilitado")
except Exception as e:
    METRICS_ENABLED = False
    logger = logging.getLogger("chatbot_app")
    logger.warning(f"‚ö†Ô∏è Sistema de m√©tricas deshabilitado: {e}")

# Configurar logging primero
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger("chatbot_app")

# Crear la aplicaci√≥n FastAPI
app = FastAPI()

# ===== CONFIGURACI√ìN DE CELERY PARA ARQUITECTURA ASINCR√ìNICA =====
celery_app = None
if CELERY_AVAILABLE:
    try:
        celery_app = Celery('chatbot_worker')
        celery_app.config_from_object({
            'broker_url': 'redis://localhost:6379/0',
            'result_backend': 'redis://localhost:6379/0',
            'task_serializer': 'json',
            'accept_content': ['json'],
            'result_serializer': 'json',
        })
        logger.info("‚úÖ Cliente Celery configurado correctamente")
    except Exception as e:
        logger.error(f"‚ùå Error configurando Celery: {e}")
        CELERY_AVAILABLE = False

# Ruta para manejar redirecciones incorrectas de /pages/index.html
@app.get("/pages/index.html")
def serve_pages_index_redirect():
    from fastapi.responses import RedirectResponse
    return RedirectResponse(url="/", status_code=301)

# Variable global para el sistema IA
ai_system_instance = None
ai_system_ready = False

# Configurar CORS con headers adicionales
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["X-Request-ID", "X-Processing-Time"]
)

# Montar archivos est√°ticos - CONFIGURACI√ìN CORREGIDA
app.mount("/static", StaticFiles(directory="../frontend"), name="static")
app.mount("/assets", StaticFiles(directory="../frontend/assets"), name="assets")
app.mount("/pages", StaticFiles(directory="../frontend/pages"), name="pages")

# Configurar executor para tareas as√≠ncronas
executor = ThreadPoolExecutor(max_workers=4)

# Ruta ra√≠z - PRINCIPAL
@app.get("/")
def serve_index():
    return FileResponse("../frontend/index.html")

# Agregar ruta adicional para servir index.html directamente
@app.get("/index.html")
def serve_index_direct():
    return FileResponse("../frontend/index.html")

# Agregar ruta espec√≠fica para el dashboard
@app.get("/dashboard")
def serve_dashboard():
    return FileResponse("../frontend/pages/dashboard.html")

@app.get("/pages/dashboard")
def serve_dashboard_pages():
    return FileResponse("../frontend/pages/dashboard.html")

# FASE 1: Ruta para dashboard de m√©tricas
@app.get("/metrics")
def serve_metrics_dashboard():
    return FileResponse("../frontend/pages/metrics.html")

@app.get("/pages/metrics")
def serve_metrics_pages():
    return FileResponse("../frontend/pages/metrics.html")

@app.on_event("startup")
async def startup_event():
    """Evento que se ejecuta al iniciar el servidor"""
    global ai_system_instance, ai_system_ready
    
    logger.info("=" * 60)
    logger.info("üöÄ INICIANDO CHATBOT EDUCATIVO")
    logger.info("=" * 60)
    
    # FIRST: Configure routes before anything else
    logger.info("üîß Configurando rutas del sistema...")
    routes_success = setup_routes()
    if routes_success:
        logger.info("‚úÖ Rutas configuradas exitosamente")
    else:
        logger.warning("‚ö†Ô∏è Problemas configurando algunas rutas")
    
    try:
        # Importar y crear instancia del sistema IA
        from ai_system import AISystem
        ai_system_instance = AISystem()
        
        # Inicializar el sistema de forma s√≠ncrona
        logger.info("üîÑ Inicializando sistema de inteligencia artificial...")
        start_time = time.time()
        
        success = ai_system_instance.initialize_system()
        
        initialization_time = time.time() - start_time
        
        if success:
            ai_system_ready = True
            logger.info("=" * 60)
            logger.info(f"‚úÖ SISTEMA LISTO EN {initialization_time:.2f} SEGUNDOS")
            logger.info(f"üß† Modelo: {'ChromaDB' if ai_system_instance.using_chroma else 'FAISS' if ai_system_instance.using_vector_db else 'Solo LLM'}")
            logger.info(f"üìö Documentos: {len(ai_system_instance.documentos)}")
            logger.info(f"üìÑ Fragmentos: {len(ai_system_instance.fragmentos)}")
            logger.info("üåü El chatbot est√° listo para recibir consultas")
            logger.info("=" * 60)
        else:
            logger.error("‚ùå Error en la inicializaci√≥n del sistema IA")
            logger.info("üîÑ Continuando con sistema b√°sico...")
            ai_system_ready = False
            
    except Exception as e:
        logger.error(f"‚ùå Error cr√≠tico en startup: {e}")
        logger.info("üîÑ Continuando sin sistema IA avanzado...")
        ai_system_ready = False

# Modelos b√°sicos
class Pregunta(BaseModel):
    texto: str
    userId: str = None
    chatToken: str = None
    history: list = None
    modelo: str = None  # Nuevo campo para el modelo seleccionado

class SessionIn(BaseModel):
    user_id: str
    session_id: str
    history: list

class SolicitudSugerencias(BaseModel):
    userId: str = None
    chatToken: str = None
    history: list = None

class FeedbackIn(BaseModel):
    user_id: str
    session_id: str
    pregunta: str
    respuesta: str
    rating: int
    comentario: str = None

# Funci√≥n para generar respuestas b√°sicas
def generar_respuesta_rapida(pregunta_texto):
    """Genera respuestas b√°sicas r√°pidas cuando el sistema IA est√° sobrecargado"""
    pregunta_lower = pregunta_texto.lower()
    
    # Respuestas r√°pidas para patrones comunes
    if any(saludo in pregunta_lower for saludo in ["hola", "mi nombre es", "me llamo", "soy"]):
        return "¬°Hola! Un gusto conocerte. Soy tu asistente virtual especializado en Fundamentos de Inteligencia Artificial. ¬øEn qu√© puedo ayudarte hoy?"
    
    if "inteligencia artificial" in pregunta_lower and any(q in pregunta_lower for q in ["qu√© es", "que es", "define"]):
        return "La Inteligencia Artificial es un campo de la inform√°tica que busca crear sistemas capaces de realizar tareas que normalmente requieren inteligencia humana, como el aprendizaje, razonamiento y toma de decisiones."
    
    if "machine learning" in pregunta_lower or "aprendizaje autom√°tico" in pregunta_lower:
        return "Machine Learning es una rama de la IA que permite a las m√°quinas aprender patrones de los datos sin ser programadas expl√≠citamente para cada tarea espec√≠fica."
    
    # Respuesta gen√©rica pero √∫til
    return f"He recibido tu pregunta sobre '{pregunta_texto}'. Te puedo ayudar con conceptos de inteligencia artificial, algoritmos, historia de la IA, machine learning y m√°s. ¬øHay algo espec√≠fico que te gustar√≠a saber?"

# Funci√≥n para guardar historial de forma segura
def save_to_history_safe(user_id, chat_token, pregunta, respuesta):
    """Guarda la interacci√≥n en el historial de forma segura y r√°pida"""
    try:
        from models import engine
        from sqlalchemy import text
        
        # Limitar la longitud de pregunta y respuesta para evitar problemas de BD
        pregunta_truncated = pregunta[:500] if len(pregunta) > 500 else pregunta
        respuesta_truncated = respuesta[:2000] if len(respuesta) > 2000 else respuesta
        
        # Crear entradas de historial
        history_entries = [
            {"sender": "user", "text": pregunta_truncated, "timestamp": datetime.now().isoformat()},
            {"sender": "bot", "text": respuesta_truncated, "timestamp": datetime.now().isoformat()}
        ]
        
        with engine.connect() as connection:
            # Verificar si existe la sesi√≥n
            existing = connection.execute(
                text("SELECT history FROM chat_sessions WHERE user_id = :user_id AND session_id = :session_id"),
                {"user_id": user_id, "session_id": chat_token}
            ).fetchone()
            
            if existing:
                # Actualizar historial existente
                current_history = []
                if existing[0]:
                    try:
                        if isinstance(existing[0], str):
                            current_history = json.loads(existing[0])
                        elif isinstance(existing[0], (list, dict)):
                            current_history = existing[0] if isinstance(existing[0], list) else [existing[0]]
                        else:
                            current_history = []
                    except json.JSONDecodeError:
                        logger.warning("Error decodificando JSON del historial, creando nuevo historial")
                        current_history = []
                
                current_history.extend(history_entries)
                
                # Limitar el historial a los √∫ltimos 50 mensajes para evitar que crezca demasiado
                if len(current_history) > 50:
                    current_history = current_history[-50:]
                
                connection.execute(
                    text("UPDATE chat_sessions SET history = :history WHERE user_id = :user_id AND session_id = :session_id"),
                    {"user_id": user_id, "session_id": chat_token, "history": json.dumps(current_history)}
                )
            else:
                # Crear nueva sesi√≥n
                connection.execute(
                    text("INSERT INTO chat_sessions (user_id, session_id, history) VALUES (:user_id, :session_id, :history)"),
                    {"user_id": user_id, "session_id": chat_token, "history": json.dumps(history_entries)}
                )
            
            connection.commit()
            logger.debug(f"Historial guardado para usuario {user_id}, sesi√≥n {chat_token}")
            
    except Exception as e:
        logger.warning(f"No se pudo guardar historial: {e}")

async def save_to_history_async(user_id, chat_token, pregunta, respuesta):
    """Versi√≥n as√≠ncrona del guardado de historial"""
    try:
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(executor, save_to_history_safe, user_id, chat_token, pregunta, respuesta)
    except Exception as e:
        logger.warning(f"Error en guardado as√≠ncrono de historial: {e}")

async def save_to_history_safe_silent(user_id, chat_token, pregunta, respuesta):
    """Versi√≥n silenciosa del guardado de historial que nunca falla"""
    try:
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(executor, lambda: save_to_history_safe(user_id, chat_token, pregunta, respuesta))
    except:
        pass  # Ignorar todos los errores

# Endpoint de verificaci√≥n de conexi√≥n b√°sica
@app.get("/check_connection")
async def check_connection():
    try:
        from models import check_db_connection
        return {"connected": check_db_connection()}
    except:
        return {"connected": False}

# Endpoint b√°sico de preguntas
@app.post("/preguntar")
async def preguntar_basic(pregunta: Pregunta):
    request_id = None
    try:
        start_time = time.time()
        respuesta = None
        
        # FASE 1: Iniciar tracking de m√©tricas
        if METRICS_ENABLED:
            model_used = pregunta.modelo or "llama3"
            request_id = start_request_tracking(
                endpoint="/preguntar",
                model_used=model_used,
                user_id=pregunta.userId or "anonymous",
                question_length=len(pregunta.texto)
            )
            logger.info(f"üìä Tracking iniciado: {request_id}")
        
        # Verificar si el sistema IA est√° listo
        if ai_system_ready and ai_system_instance:
            try:
                logger.info(f"Procesando pregunta con IA: {pregunta.texto}")
                
                # Tracking de tiempo de vector search y LLM
                vector_start = time.time()
                
                # Ejecutar procesamiento de pregunta
                loop = asyncio.get_event_loop()
                respuesta = await loop.run_in_executor(executor, ai_system_instance.process_question, pregunta)
                
                vector_time = time.time() - vector_start
                processing_time = time.time() - start_time
                
                logger.info(f"Respuesta IA generada en {processing_time:.2f}s")
                
                # FASE 1: Finalizar tracking exitoso
                if METRICS_ENABLED and request_id:
                    end_request_tracking(
                        request_id=request_id,
                        status="success",
                        response_length=len(respuesta) if respuesta else 0,
                        vector_search_time=vector_time,
                        llm_processing_time=processing_time
                    )
                    
            except Exception as ai_error:
                logger.error(f"Error en sistema IA: {ai_error}")
                respuesta = None
                
                # FASE 1: Tracking de error en IA
                if METRICS_ENABLED and request_id:
                    end_request_tracking(
                        request_id=request_id,
                        status="error",
                        error_details=f"AI Error: {str(ai_error)[:200]}"
                    )
        else:
            logger.info("Sistema IA no disponible, usando respuesta b√°sica")
        
        # Si no hay respuesta del sistema IA, usar respuesta b√°sica
        if not respuesta:
            respuesta = generar_respuesta_rapida(pregunta.texto)
            logger.info("Usando respuesta b√°sica")
            
            # FASE 1: Tracking de respuesta b√°sica
            if METRICS_ENABLED and request_id:
                end_request_tracking(
                    request_id=request_id,
                    status="fallback",
                    response_length=len(respuesta),
                    error_details="AI system not available - fallback response"
                )
        
        # Validar que la respuesta no est√© vac√≠a
        if not respuesta or respuesta.strip() == "":
            respuesta = "Lo siento, no pude generar una respuesta adecuada. ¬øPodr√≠as reformular tu pregunta?"
        
        # Intentar guardar historial sin que falle la respuesta
        if pregunta.userId and pregunta.chatToken:
            try:
                asyncio.create_task(save_to_history_safe_silent(pregunta.userId, pregunta.chatToken, pregunta.texto, respuesta))
            except:
                pass  # Ignorar errores de historial completamente
        
        total_time = time.time() - start_time
        logger.info(f"Respuesta enviada: {len(respuesta)} caracteres en {total_time:.2f}s")
        
        return {"respuesta": respuesta, "status": "success"}
        
    except Exception as e:
        logger.error(f"Error en preguntar_basic: {e}")
        
        # FASE 1: Tracking de error general
        if METRICS_ENABLED and request_id:
            end_request_tracking(
                request_id=request_id,
                status="error",
                error_details=f"General Error: {str(e)[:200]}"
            )
        
        return {"respuesta": "Lo siento, ocurri√≥ un error inesperado. Por favor, int√©ntalo de nuevo.", "status": "error"}

@app.get("/ai_status")
async def get_ai_status():
    """Endpoint para verificar el estado del sistema IA"""
    global ai_system_ready, ai_system_instance
    
    try:
        if ai_system_ready and ai_system_instance:
            return {
                "success": True,
                "ready": True,
                "message": "Sistema IA listo y operativo",
                "details": {
                    "using_chroma": ai_system_instance.using_chroma,
                    "using_vector_db": ai_system_instance.using_vector_db,
                    "documentos_count": len(ai_system_instance.documentos),
                    "fragmentos_count": len(ai_system_instance.fragmentos),
                    "llm_available": ai_system_instance.llm is not None
                }
            }
        else:
            return {
                "success": True,
                "ready": False,
                "message": "Sistema IA no disponible - usando modo b√°sico",
                "details": {}
            }
    except Exception as e:
        logger.error(f"Error obteniendo estado IA: {e}")
        return {
            "success": False,
            "ready": False,
            "message": f"Error: {str(e)}",
            "details": {}
        }

@app.get("/ai_diagnostics")
async def get_ai_diagnostics():
    """Endpoint para obtener diagn√≥sticos detallados del sistema de IA"""
    global ai_system_instance
    
    try:
        if ai_system_instance and hasattr(ai_system_instance, 'get_error_diagnostics'):
            diagnostics = ai_system_instance.get_error_diagnostics()
            return {"success": True, "diagnostics": diagnostics}
        else:
            return {
                "success": False, 
                "message": "Sistema IA no disponible",
                "basic_info": get_ai_system_info()
            }
    except Exception as e:
        logger.error(f"Error obteniendo diagn√≥sticos: {e}")
        return {
            "success": False, 
            "error": str(e),
            "basic_info": get_ai_system_info()
        }

# Nuevos endpoints para gesti√≥n de modelos
@app.get("/models/available")
async def get_available_models():
    """Retorna los modelos disponibles"""
    global ai_system_instance
    try:
        if ai_system_instance:
            from config import AVAILABLE_MODELS
            return {
                "models": AVAILABLE_MODELS,
                "current_model": ai_system_instance.get_current_model()
            }
        else:
            from config import AVAILABLE_MODELS, DEFAULT_MODEL
            return {
                "models": AVAILABLE_MODELS,
                "current_model": DEFAULT_MODEL
            }
    except Exception as e:
        logger.error(f"Error obteniendo modelos: {e}")
        return {"error": str(e), "models": {}, "current_model": None}

@app.post("/models/switch")
async def switch_model(request: Request):
    """Cambia el modelo activo"""
    global ai_system_instance
    try:
        data = await request.json()
        model_name = data.get("model")
        
        if not model_name:
            return {"success": False, "error": "Modelo no especificado"}
            
        if ai_system_instance:
            # FASE 1: Registrar cambio de modelo en m√©tricas
            current_model = ai_system_instance.get_current_model()
            if METRICS_ENABLED:
                record_model_switch(current_model, model_name)
            
            success = ai_system_instance.switch_model(model_name)
            if success:
                # Obtener estado del contexto despu√©s del cambio
                context_status = ai_system_instance.get_context_status()
                return {
                    "success": True, 
                    "message": f"Modelo cambiado a {model_name}",
                    "current_model": ai_system_instance.get_current_model(),
                    "context_status": context_status
                }
            else:
                return {"success": False, "error": f"Error cambiando modelo a {model_name}"}
        else:
            return {"success": False, "error": "Sistema IA no inicializado"}
            
    except Exception as e:
        logger.error(f"Error cambiando modelo: {e}")
        return {"success": False, "error": str(e)}

@app.get("/models/context_status")
async def get_context_status():
    """Retorna el estado actual del contexto del sistema"""
    global ai_system_instance
    try:
        if ai_system_instance:
            status = ai_system_instance.get_context_status()
            return {
                "success": True,
                "context_status": status
            }
        else:
            return {
                "success": False,
                "error": "Sistema IA no inicializado",
                "context_status": {}
            }
    except Exception as e:
        logger.error(f"Error obteniendo estado del contexto: {e}")
        return {"success": False, "error": str(e), "context_status": {}}

# Endpoint optimizado para historial que no interfiera
@app.get("/chat/history")
def get_history_basic(user_id: str, session_id: str):
    try:
        from models import engine
        from sqlalchemy import text
        
        with engine.connect() as connection:
            result = connection.execute(
                text("SELECT history FROM chat_sessions WHERE user_id = :user_id AND session_id = :session_id"),
                {"user_id": user_id, "session_id": session_id}
            ).fetchone()
            
            if result and result[0]:
                if isinstance(result[0], (dict, list)):
                    return result[0]
                else:
                    return json.loads(result[0])
            return []
    except:
        # Devolver array vac√≠o sin logging de error para evitar spam
        return []

# Otros endpoints b√°sicos del chat
@app.post("/chat/history")
def save_history_basic(data: SessionIn):
    try:
        from models import engine
        from sqlalchemy import text
        
        history_json = json.dumps(data.history)
        
        with engine.connect() as connection:
            exists = connection.execute(
                text("SELECT 1 FROM chat_sessions WHERE user_id = :user_id AND session_id = :session_id"),
                {"user_id": data.user_id, "session_id": data.session_id}
            ).fetchone()
            
            if exists:
                connection.execute(
                    text("UPDATE chat_sessions SET history = :history WHERE user_id = :user_id AND session_id = :session_id"),
                    {"user_id": data.user_id, "session_id": data.session_id, "history": history_json}
                )
            else:
                connection.execute(
                    text("INSERT INTO chat_sessions (user_id, session_id, history) VALUES (:user_id, :session_id, :history)"),
                    {"user_id": data.user_id, "session_id": data.session_id, "history": history_json}
                )
            
            connection.commit()
            return {"ok": True}
    except Exception as db_error:
        logger.warning(f"No se pudo guardar en BD: {db_error}")
        return {"ok": True}

@app.get("/chat/sessions")
def get_sessions_basic(user_id: str):
    try:
        from models import engine
        from sqlalchemy import text
        
        with engine.connect() as connection:
            result = connection.execute(
                text("SELECT session_id, updated_at as created_at FROM chat_sessions WHERE user_id = :user_id ORDER BY updated_at DESC"),
                {"user_id": user_id}
            ).fetchall()
            return [{"session_id": row[0], "created_at": row[1]} for row in result]
    except:
        return []

@app.get("/chat/message_ratings")
def get_ratings_basic(user_id: str, session_id: str):
    try:
        from models import engine
        from sqlalchemy import text
        
        with engine.connect() as connection:
            result = connection.execute(
                text("""
                    SELECT pregunta, respuesta, rating 
                    FROM feedback 
                    WHERE user_id = :user_id AND session_id = :session_id
                """),
                {"user_id": user_id, "session_id": session_id}
            ).fetchall()
            
            return [
                {
                    "pregunta": row[0],
                    "respuesta": row[1],
                    "rating": row[2]
                } for row in result
            ]
    except:
        return []

@app.delete("/chat/session")
def delete_session_basic(user_id: str, session_id: str):
    try:
        from models import SessionLocal, ChatSession
        
        with SessionLocal() as db:
            session = db.query(ChatSession).filter(
                ChatSession.user_id == user_id,
                ChatSession.session_id == session_id
            ).first()
            
            if session:
                db.delete(session)
                db.commit()
                return {"ok": True}
            else:
                return {"ok": False, "error": "Sesi√≥n no encontrada"}
    except:
        return {"ok": True}

@app.post("/chat/feedback")
def save_feedback_basic(fb: FeedbackIn):
    try:
        from models import engine
        from sqlalchemy import text
        
        with engine.connect() as connection:
            connection.execute(
                text("""
                    INSERT INTO feedback (user_id, session_id, pregunta, respuesta, rating, comentario) 
                    VALUES (:user_id, :session_id, :pregunta, :respuesta, :rating, :comentario)
                """),
                {"user_id": fb.user_id, "session_id": fb.session_id, "pregunta": fb.pregunta, 
                 "respuesta": fb.respuesta, "rating": fb.rating, "comentario": fb.comentario}
            )
            connection.commit()
            return {"ok": True}
    except:
        return {"ok": True}

# Rutas de autenticaci√≥n b√°sicas
@app.post("/auth/login")
async def login_basic(request: Request):
    try:
        data = await request.json()
        email = data.get("email")
        password = data.get("password")
        
        try:
            from models import SessionLocal, User, pwd_context
            
            with SessionLocal() as db:
                user = db.query(User).filter(User.email == email).first()
                
                if not user:
                    return {"success": False, "message": "Credenciales incorrectas"}
                
                if not pwd_context.verify(password, user.password):
                    return {"success": False, "message": "Credenciales incorrectas"}
                
                # Asegurar que permisos tenga un valor por defecto
                permisos = user.permisos if user.permisos is not None else 'usuario'
                
                logger.info(f"Login exitoso en app.py: {email}, permisos: {permisos}")
                
                return {
                    "success": True,
                    "user": {
                        "id": user.id,
                        "nombre": user.nombre,
                        "email": user.email,
                        "permisos": permisos  # Agregar permisos aqu√≠
                    }
                }
        except Exception as db_error:
            logger.warning(f"Error de BD en login: {db_error}")
            # Autenticaci√≥n b√°sica de prueba si no hay BD
            if email == "test@test.com" and password == "123456":
                return {
                    "success": True,
                    "user": {
                        "id": 5,
                        "nombre": "Usuario Test",
                        "email": "test@test.com",
                        "permisos": "usuario"  # Agregar permisos por defecto
                    }
                }
            else:
                return {"success": False, "message": "Credenciales incorrectas"}
            
    except Exception as e:
        logger.error(f"Error en login_basic: {e}")
        return {"success": False, "message": "Error en login"}

@app.post("/auth/register")
async def register_basic(request: Request):
    try:
        data = await request.json()
        nombre = data.get("nombre")
        email = data.get("email")
        password = data.get("password")
        
        if not all([nombre, email, password]):
            return {"success": False, "message": "Todos los campos son requeridos"}
        
        try:
            from models import SessionLocal, User, pwd_context
            from datetime import datetime
            
            with SessionLocal() as db:
                existing_user = db.query(User).filter(User.email == email).first()
                if existing_user:
                    return {"success": False, "message": "El email ya est√° registrado"}
                
                hashed_password = pwd_context.hash(password)
                new_user = User(
                    nombre=nombre,
                    email=email,
                    password=hashed_password,
                    permisos='usuario',  # Asignar permisos por defecto
                    created_at=datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                )
                db.add(new_user)
                db.commit()
                db.refresh(new_user)
                
                return {
                    "success": True,
                    "message": "Usuario registrado exitosamente",
                    "user": {
                        "id": new_user.id,
                        "nombre": new_user.nombre,
                        "email": new_user.email,
                        "permisos": new_user.permisos or 'usuario'  # Incluir permisos
                    }
                }
        except Exception as db_error:
            logger.warning(f"Error de BD en registro: {db_error}")
            return {
                "success": True,
                "message": "Usuario registrado exitosamente (modo prueba)",
                "user": {
                    "id": 6,
                    "nombre": nombre,
                    "email": email,
                    "permisos": "usuario"  # Agregar permisos por defecto
                }
            }
            
    except Exception as e:
        logger.error(f"Error en register_basic: {e}")
        return {"success": False, "message": "Error en registro"}

# Endpoint b√°sico de sugerencias - OPTIMIZADO
@app.post("/sugerencias")
async def sugerencias_dinamicas(solicitud: SolicitudSugerencias):
    try:
        start_time = time.time()
        
        # Verificar si tenemos historial de conversaci√≥n
        historial = solicitud.history if solicitud.history else []
        
        # Si el sistema IA est√° disponible, generar sugerencias din√°micas con timeout
        if ai_system_ready and ai_system_instance and hasattr(ai_system_instance, 'generate_dynamic_suggestions'):
            try:
                logger.info("Generando sugerencias din√°micas basadas en conversaci√≥n")
                
                # Ejecutar generaci√≥n de sugerencias con timeout de 8 segundos
                loop = asyncio.get_event_loop()
                sugerencias_task = loop.run_in_executor(
                    executor, 
                    ai_system_instance.generate_dynamic_suggestions, 
                    historial
                )
                
                # Usar timeout para evitar esperas largas
                try:
                    sugerencias_dinamicas = await asyncio.wait_for(sugerencias_task, timeout=8.0)
                    
                    processing_time = time.time() - start_time
                    logger.info(f"Sugerencias din√°micas generadas en {processing_time:.2f}s")
                    
                    return {"sugerencias": sugerencias_dinamicas}
                    
                except asyncio.TimeoutError:
                    logger.warning("Timeout generando sugerencias din√°micas, usando fallback")
                    # Cancelar la tarea si es posible
                    sugerencias_task.cancel()
                
            except Exception as ai_error:
                logger.error(f"Error generando sugerencias din√°micas: {ai_error}")
        else:
            logger.info("Sistema IA no disponible para sugerencias, usando b√°sicas")
        
        # Sugerencias b√°sicas como fallback (m√°s r√°pidas)
        sugerencias_basicas = generar_sugerencias_basicas_rapidas(historial)
        
        total_time = time.time() - start_time
        logger.info(f"Sugerencias b√°sicas generadas en {total_time:.2f}s")
        
        return {"sugerencias": sugerencias_basicas}
        
    except Exception as e:
        logger.error(f"Error en endpoint de sugerencias: {e}")
        return {
            "sugerencias": [
                "¬øQu√© es la inteligencia artificial?",
                "¬øC√≥mo funciona el machine learning?",
                "¬øCu√°les son los algoritmos principales?"
            ]
        }

def generar_sugerencias_basicas_rapidas(historial):
    """Versi√≥n optimizada de sugerencias b√°sicas para m√°xima velocidad."""
    try:
        if not historial or len(historial) == 0:
            return [
                "¬øQu√© es la inteligencia artificial?",
                "¬øC√≥mo funciona el machine learning?",
                "¬øCu√°les son los algoritmos principales?"
            ]
        
        # Solo analizar la √∫ltima respuesta del bot para velocidad
        ultima_respuesta = ""
        for mensaje in reversed(historial):
            if isinstance(mensaje, dict) and mensaje.get('sender') == 'bot':
                ultima_respuesta = mensaje.get('text', '').lower()
                break
        
        # Sugerencias r√°pidas basadas en palabras clave simples
        if 'machine learning' in ultima_respuesta or 'ml' in ultima_respuesta:
            return [
                "¬øQu√© tipos de ML existen?",
                "¬øC√≥mo funciona el aprendizaje supervisado?",
                "¬øCu√°les son las aplicaciones del ML?"
            ]
        elif 'algoritmo' in ultima_respuesta:
            return [
                "¬øQu√© algoritmos son m√°s utilizados?",
                "¬øC√≥mo se eval√∫a un algoritmo?",
                "¬øCu√°l es mejor para clasificaci√≥n?"
            ]
        elif 'neural' in ultima_respuesta or 'red' in ultima_respuesta:
            return [
                "¬øC√≥mo funcionan las redes profundas?",
                "¬øQu√© es el backpropagation?",
                "¬øCu√°les son las aplicaciones principales?"
            ]
        elif 'datos' in ultima_respuesta or 'entrenamiento' in ultima_respuesta:
            return [
                "¬øC√≥mo preparar los datos?",
                "¬øQu√© es el overfitting?",
                "¬øCu√°ntos datos necesito?"
            ]
        else:
            return [
                "¬øPodr√≠as dar ejemplos espec√≠ficos?",
                "¬øC√≥mo se aplica en la pr√°ctica?",
                "¬øQu√© conceptos est√°n relacionados?"
            ]
            
    except Exception as e:
        logger.error(f"Error generando sugerencias b√°sicas r√°pidas: {e}")
        return [
            "¬øQu√© es la inteligencia artificial?",
            "¬øC√≥mo funciona el machine learning?",
            "¬øCu√°les son los algoritmos principales?"
        ]

# Funci√≥n para configurar las rutas despu√©s de que todo est√© cargado
def setup_routes():
    """Configura las rutas de la aplicaci√≥n de forma diferida."""
    logger.info("üîß STARTING route configuration process...")
    all_routes_configured_successfully = True

    # Configure Auth Router
    try:
        from auth import router as auth_router
        app.include_router(auth_router, prefix="/auth", tags=["auth"])
        logger.info("‚úÖ Auth router configured and included successfully.")
    except ImportError as e:
        logger.error(f"‚ùå Failed to import auth_router: {e}")
        all_routes_configured_successfully = False
    except Exception as e:
        logger.error(f"‚ùå Error configuring auth_router: {e}")
        all_routes_configured_successfully = False

    # Configure Chat Router
    try:
        from chat import router as chat_router
        app.include_router(chat_router, prefix="/chat", tags=["chat"])
        logger.info("‚úÖ Chat router configured and included successfully.")
        
        # Compatibility routes from chat module
        try:
            from chat import preguntar as chat_preguntar_func, generar_sugerencias as chat_sugerencias_func
            
            @app.post("/sugerencias_compat")
            def generar_sugerencias_compat(solicitud: SolicitudSugerencias):
                return chat_sugerencias_func(solicitud)
                
            @app.post("/preguntar_compat") 
            def preguntar_compat(pregunta_data: Pregunta):
                return chat_preguntar_func(pregunta_data)
            logger.info("‚úÖ Chat compatibility routes configured.")
        except ImportError as chat_funcs_error:
            logger.warning(f"‚ö†Ô∏è Could not import chat functions for compatibility routes: {chat_funcs_error}")

    except ImportError as e:
        logger.error(f"‚ùå Failed to import chat_router: {e}")
        all_routes_configured_successfully = False
    except Exception as e:
        logger.error(f"‚ùå Error configuring chat_router: {e}")
        all_routes_configured_successfully = False

    # Configure Dashboard Router - ENHANCED CRITICAL SECTION
    dashboard_success = False
    try:
        logger.info("üîß Attempting to import dashboard router...")
        
        # Force fresh import of dashboard module
        import importlib
        import sys
        if 'dashboard' in sys.modules:
            importlib.reload(sys.modules['dashboard'])
        
        from dashboard import router as dashboard_router
        logger.info(f"‚úÖ Successfully imported dashboard_router: {type(dashboard_router)}")
        
        # Detailed inspection of dashboard router
        if dashboard_router is None:
            logger.error("‚ùå CRITICAL: dashboard_router is None after import!")
            raise ImportError("dashboard_router is None")
        
        if not hasattr(dashboard_router, 'routes'):
            logger.error("‚ùå CRITICAL: dashboard_router missing 'routes' attribute!")
            raise ImportError("dashboard_router missing routes")
        
        routes_count = len(dashboard_router.routes)
        logger.info(f"üìä Dashboard router contains {routes_count} routes")
        
        if routes_count == 0:
            logger.error("‚ùå CRITICAL: Dashboard router has 0 routes!")
            raise ImportError("Dashboard router has no routes")
        
        # Log each route in detail
        for idx, route in enumerate(dashboard_router.routes):
            if hasattr(route, 'path') and hasattr(route, 'methods'):
                methods = ', '.join(route.methods)
                logger.info(f"  üìã Route [{idx}]: {methods} {route.path}")
            else:
                logger.info(f"  üìã Route [{idx}]: {type(route)} - path: {getattr(route, 'path', 'MISSING')}")
        
        # Include dashboard router with enhanced logging
        logger.info("üîß Including dashboard router in main FastAPI app...")
        
        # Count routes before inclusion
        routes_before = len(app.routes)
        dashboard_routes_before = len([r for r in app.routes if hasattr(r, 'path') and r.path.startswith('/dashboard')])
        
        logger.info(f"üìä App routes before dashboard inclusion: {routes_before} (dashboard: {dashboard_routes_before})")
        
        # Include the router
        app.include_router(dashboard_router, prefix="/dashboard", tags=["dashboard"])
        
        # Count routes after inclusion
        routes_after = len(app.routes)
        dashboard_routes_after = len([r for r in app.routes if hasattr(r, 'path') and r.path.startswith('/dashboard')])
        
        logger.info(f"üìä App routes after dashboard inclusion: {routes_after} (dashboard: {dashboard_routes_after})")
        logger.info(f"üìä Routes added: {routes_after - routes_before}")
        
        if dashboard_routes_after == 0:
            logger.error("‚ùå CRITICAL: No dashboard routes found on app after inclusion!")
            raise Exception("Dashboard routes not registered on app")
        elif dashboard_routes_after != routes_count:
            logger.warning(f"‚ö†Ô∏è Route count mismatch: expected {routes_count}, got {dashboard_routes_after}")
        else:
            logger.info("‚úÖ Dashboard routes successfully registered!")
            dashboard_success = True
        
        # Verify specific routes exist
        dashboard_routes = [r for r in app.routes if hasattr(r, 'path') and r.path.startswith('/dashboard')]
        for route in dashboard_routes:
            if hasattr(route, 'methods') and hasattr(route, 'path'):
                methods = ', '.join(route.methods)
                logger.info(f"  ‚úÖ VERIFIED: {methods} {route.path}")
        
        if not dashboard_success:
            logger.error("‚ùå Dashboard router inclusion verification failed")
            all_routes_configured_successfully = False
        
    except ImportError as e:
        logger.error(f"‚ùå FAILED to import dashboard module: {e}")
        all_routes_configured_successfully = False
        # Try fallback manual route registration
        logger.info("üîß Attempting fallback dashboard route registration...")
        try:
            register_dashboard_routes_fallback()
            logger.info("‚úÖ Fallback dashboard routes registered")
        except Exception as fallback_error:
            logger.error(f"‚ùå Fallback route registration failed: {fallback_error}")
            
    except Exception as e:
        logger.error(f"‚ùå Unexpected error configuring dashboard: {e}", exc_info=True)
        all_routes_configured_successfully = False

    # Final comprehensive verification
    total_routes = len(app.routes)
    dashboard_final_count = len([r for r in app.routes if hasattr(r, 'path') and r.path.startswith('/dashboard')])
    auth_routes = len([r for r in app.routes if hasattr(r, 'path') and r.path.startswith('/auth')])
    chat_routes = len([r for r in app.routes if hasattr(r, 'path') and r.path.startswith('/chat')])
    
    logger.info("=" * 50)
    logger.info("üìã FINAL ROUTE CONFIGURATION SUMMARY:")
    logger.info(f"  üìä Total routes: {total_routes}")
    logger.info(f"  üîê Auth routes: {auth_routes}")
    logger.info(f"  üí¨ Chat routes: {chat_routes}")
    logger.info(f"  üìä Dashboard routes: {dashboard_final_count}")
    logger.info("=" * 50)
    
    if all_routes_configured_successfully and dashboard_final_count > 0:
        logger.info("‚úÖ Route configuration completed successfully!")
    else:
        logger.warning("‚ö†Ô∏è Route configuration completed with issues!")
        
    return all_routes_configured_successfully

def register_dashboard_routes_fallback():
    """Fallback function to manually register dashboard routes if router inclusion fails"""
    logger.info("üîß Registering dashboard routes manually as fallback...")
    
    # Import dashboard functions directly
    try:
        from dashboard import (
            get_dashboard_stats, get_user_sessions_stats, get_feedback_analysis,
            get_dashboard_users, get_system_health, get_dashboard_analytics,
            check_dashboard_access
        )
        
        # Register routes manually
        app.add_api_route("/dashboard/stats", get_dashboard_stats, methods=["GET"], tags=["dashboard"])
        app.add_api_route("/dashboard/user-sessions", get_user_sessions_stats, methods=["GET"], tags=["dashboard"])
        app.add_api_route("/dashboard/feedback-analysis", get_feedback_analysis, methods=["GET"], tags=["dashboard"])
        app.add_api_route("/dashboard/users", get_dashboard_users, methods=["GET"], tags=["dashboard"])
        app.add_api_route("/dashboard/system-health", get_system_health, methods=["GET"], tags=["dashboard"])
        app.add_api_route("/dashboard/analytics", get_dashboard_analytics, methods=["GET"], tags=["dashboard"])
        app.add_api_route("/dashboard/check-access", check_dashboard_access, methods=["GET"], tags=["dashboard"])
        
        logger.info("‚úÖ Fallback dashboard routes registered successfully")
        
    except ImportError as e:
        logger.error(f"‚ùå Failed to import dashboard functions for fallback: {e}")
        raise
    except Exception as e:
        logger.error(f"‚ùå Failed to register fallback dashboard routes: {e}")
        raise

# Funci√≥n para obtener informaci√≥n del sistema IA
def get_ai_system_info():
    """Obtiene informaci√≥n del sistema de IA de forma segura"""
    global ai_system_instance
    
    try:
        if ai_system_instance:
            return {
                "using_chroma": getattr(ai_system_instance, 'using_chroma', False),
                "using_vector_db": getattr(ai_system_instance, 'using_vector_db', False),
                "documentos_count": len(getattr(ai_system_instance, 'documentos', [])),
                "fragmentos_count": len(getattr(ai_system_instance, 'fragmentos', [])),
                "llm_available": getattr(ai_system_instance, 'llm', None) is not None,
                "cadena_available": getattr(ai_system_instance, 'cadena', None) is not None,
                "is_ready": ai_system_ready
            }
        else:
            return {
                "using_chroma": False,
                "using_vector_db": False,
                "documentos_count": 0,
                "fragmentos_count": 0,
                "llm_available": False,
                "cadena_available": False,
                "error_details": "Sistema no disponible"
            }
    except Exception as e:
        return {
            "error": str(e),
            "using_chroma": False,
            "using_vector_db": False,
            "documentos_count": 0,
            "fragmentos_count": 0,
            "llm_available": False,
            "cadena_available": False
        }

# ===============================================
# ENDPOINTS DE M√âTRICAS - FASE 1
# ===============================================

@app.get("/metrics/summary")
async def get_metrics_summary_endpoint():
    """Obtiene resumen completo de m√©tricas del sistema"""
    try:
        if not METRICS_ENABLED:
            return {"error": "Sistema de m√©tricas no disponible", "enabled": False}
        
        summary = get_metrics_summary()
        return {
            "success": True,
            "enabled": True,
            "data": summary,
            "message": "M√©tricas obtenidas exitosamente"
        }
    except Exception as e:
        logger.error(f"Error obteniendo m√©tricas: {e}")
        return {"success": False, "error": str(e), "enabled": METRICS_ENABLED}

@app.get("/metrics/bottlenecks")
async def get_bottleneck_analysis_endpoint():
    """Analiza cuellos de botella y recomienda optimizaciones"""
    try:
        if not METRICS_ENABLED:
            return {"error": "Sistema de m√©tricas no disponible", "enabled": False}
        
        analysis = get_bottleneck_analysis()
        return {
            "success": True,
            "enabled": True,
            "analysis": analysis,
            "message": "An√°lisis de cuellos de botella completado"
        }
    except Exception as e:
        logger.error(f"Error analizando cuellos de botella: {e}")
        return {"success": False, "error": str(e), "enabled": METRICS_ENABLED}

@app.get("/metrics/performance")
async def get_performance_metrics():
    """Obtiene m√©tricas espec√≠ficas de rendimiento"""
    try:
        if not METRICS_ENABLED:
            return {"error": "Sistema de m√©tricas no disponible", "enabled": False}
        
        summary = get_metrics_summary()
        
        # Extraer solo m√©tricas de rendimiento
        performance_data = {
            "response_times": summary.get("performance", {}),
            "system_resources": summary.get("system", {}),
            "model_performance": summary.get("models", {}),
            "active_requests": summary.get("general", {}).get("active_requests", 0),
            "error_rate": summary.get("general", {}).get("error_rate", 0),
            "timestamp": summary.get("timestamp")
        }
        
        return {
            "success": True,
            "enabled": True,
            "performance": performance_data,
            "recommendations": get_performance_recommendations(performance_data)
        }
    except Exception as e:
        logger.error(f"Error obteniendo m√©tricas de rendimiento: {e}")
        return {"success": False, "error": str(e), "enabled": METRICS_ENABLED}

@app.get("/metrics/queue-readiness")
async def get_queue_readiness():
    """Eval√∫a si el sistema est√° listo para implementar colas"""
    try:
        if not METRICS_ENABLED:
            return {"error": "Sistema de m√©tricas no disponible", "enabled": False}
        
        bottleneck_analysis = get_bottleneck_analysis()
        summary = get_metrics_summary()
        
        # Criterios para determinar necesidad de cola
        queue_criteria = {
            "high_response_times": summary.get("performance", {}).get("avg_response_time_hour", 0) > 3.0,
            "high_error_rate": summary.get("general", {}).get("error_rate", 0) > 5.0,
            "many_active_requests": summary.get("general", {}).get("active_requests", 0) > 3,
            "high_cpu_usage": summary.get("system", {}).get("cpu_percent", 0) > 70,
            "slow_requests_detected": len([r for r in bottleneck_analysis.get("performance_analysis", {}).get("slow_requests_count", 0)]) > 5
        }
        
        needs_queue = any(queue_criteria.values())
        
        priority_level = "ALTA" if sum(queue_criteria.values()) >= 3 else "MEDIA" if any(queue_criteria.values()) else "BAJA"
        
        recommendations = []
        if queue_criteria["high_response_times"]:
            recommendations.append("üöÄ Implementar cola de prioridad para requests lentas")
        if queue_criteria["high_error_rate"]:
            recommendations.append("üîÑ Sistema de reintentos con backoff exponencial")
        if queue_criteria["many_active_requests"]:
            recommendations.append("‚ö° Pool de workers dedicados")
        if queue_criteria["high_cpu_usage"]:
            recommendations.append("üíª Distribuci√≥n de carga entre procesos")
        
        return {
            "success": True,
            "queue_readiness": {
                "needs_queue": needs_queue,
                "priority_level": priority_level,
                "criteria_met": queue_criteria,
                "recommendations": recommendations,
                "estimated_improvement": "30-60% reducci√≥n en tiempo de respuesta" if needs_queue else "Mejoras menores esperadas",
                "next_phase_ready": needs_queue
            },
            "current_metrics": {
                "avg_response_time": summary.get("performance", {}).get("avg_response_time_hour", 0),
                "error_rate": summary.get("general", {}).get("error_rate", 0),
                "active_requests": summary.get("general", {}).get("active_requests", 0),
                "cpu_usage": summary.get("system", {}).get("cpu_percent", 0)
            }
        }
    except Exception as e:
        logger.error(f"Error evaluando readiness para cola: {e}")
        return {"success": False, "error": str(e), "enabled": METRICS_ENABLED}

def get_performance_recommendations(performance_data):
    """Genera recomendaciones basadas en m√©tricas de rendimiento"""
    recommendations = []
    
    avg_time = performance_data.get("response_times", {}).get("avg_response_time_hour", 0)
    error_rate = performance_data.get("error_rate", 0)
    cpu_usage = performance_data.get("system_resources", {}).get("cpu_percent", 0)
    memory_usage = performance_data.get("system_resources", {}).get("memory_percent", 0)
    
    if avg_time > 5:
        recommendations.append("‚è±Ô∏è Tiempos de respuesta altos - considerar optimizaci√≥n de consultas")
    if avg_time > 10:
        recommendations.append("üö® Tiempos cr√≠ticos - implementar cola urgentemente")
    
    if error_rate > 5:
        recommendations.append("üîß Alta tasa de errores - revisar estabilidad del sistema")
    if error_rate > 10:
        recommendations.append("‚ö†Ô∏è Tasa de errores cr√≠tica - implementar circuit breaker")
    
    if cpu_usage > 80:
        recommendations.append("üî• CPU sobrecargado - distribuir carga")
    if memory_usage > 85:
        recommendations.append("üíæ Memoria alta - optimizar cache y liberaci√≥n de recursos")
    
    if not recommendations:
        recommendations.append("‚úÖ Sistema funcionando dentro de par√°metros normales")
    
    return recommendations

# ===============================================
# ENDPOINTS ASINCR√ìNICOS - FASE 1
# ===============================================

# Modelos para endpoints asincr√≥nicos
class AsyncChatRequest(BaseModel):
    texto: str
    userId: str = None
    chatToken: str = None
    modelo: str = None
    conversation_id: str = None

class AsyncChatResponse(BaseModel):
    task_id: str
    status: str
    message: str
    estimated_time: int = None

class TaskStatusResponse(BaseModel):
    task_id: str
    status: str
    result: dict = None
    progress: int = None
    error: str = None

@app.post("/chat/async", response_model=AsyncChatResponse)
async def chat_async(request: AsyncChatRequest):
    """
    Endpoint asincr√≥nico para procesamiento de chat
    Retorna task_id inmediatamente, procesamiento en segundo plano
    """
    if not CELERY_AVAILABLE or not celery_app:
        # Fallback al m√©todo sincr√≥nico si Celery no est√° disponible
        return await fallback_to_sync_chat(request)
    
    try:
        # Generar ID √∫nico para la conversaci√≥n si no se proporciona
        conversation_id = request.conversation_id or str(uuid.uuid4())
        
        # Enviar tarea a Celery worker
        task = celery_app.send_task(
            'celery_worker.process_chat_task',
            args=[
                request.texto,
                request.modelo,
                conversation_id
            ],
            kwargs={},
            task_id=str(uuid.uuid4())
        )
        
        logger.info(f"üöÄ Tarea async creada: {task.id}")
        logger.info(f"   - Input: {request.texto[:50]}...")
        logger.info(f"   - Modelo: {request.modelo or 'default'}")
        
        return AsyncChatResponse(
            task_id=task.id,
            status="accepted",
            message="Consulta enviada para procesamiento asincr√≥nico",
            estimated_time=30
        )
        
    except Exception as e:
        logger.error(f"‚ùå Error creando tarea async: {e}")
        # Fallback al m√©todo sincr√≥nico
        return await fallback_to_sync_chat(request)

@app.get("/chat/status/{task_id}", response_model=TaskStatusResponse)
async def get_task_status(task_id: str):
    """
    Obtener el estado de una tarea asincr√≥nica
    """
    if not CELERY_AVAILABLE or not celery_app:
        return TaskStatusResponse(
            task_id=task_id,
            status="error",
            error="Celery no disponible"
        )
    
    try:
        # Obtener resultado de Celery
        result = AsyncResult(task_id, app=celery_app)
        
        if result.state == 'PENDING':
            response = TaskStatusResponse(
                task_id=task_id,
                status="pending",
                progress=0
            )
        elif result.state == 'PROCESSING':
            progress = result.info.get('progress', 50) if result.info else 50
            response = TaskStatusResponse(
                task_id=task_id,
                status="processing",
                progress=progress,
                result={"status": result.info.get('status', 'Procesando...')} if result.info else None
            )
        elif result.state == 'SUCCESS':
            response = TaskStatusResponse(
                task_id=task_id,
                status="completed",
                progress=100,
                result=result.result
            )
        elif result.state == 'FAILURE':
            response = TaskStatusResponse(
                task_id=task_id,
                status="failed",
                progress=0,
                error=str(result.info)
            )
        else:
            response = TaskStatusResponse(
                task_id=task_id,
                status=result.state.lower(),
                progress=0
            )
        
        return response
        
    except Exception as e:
        logger.error(f"‚ùå Error obteniendo estado de tarea {task_id}: {e}")
        return TaskStatusResponse(
            task_id=task_id,
            status="error",
            error=str(e)
        )

@app.post("/chat/switch_model_async")
async def switch_model_async(model_name: str):
    """
    Cambiar modelo de forma asincr√≥nica
    """
    if not CELERY_AVAILABLE or not celery_app:
        return {"error": "Celery no disponible", "success": False}
    
    try:
        task = celery_app.send_task(
            'chatbot_worker.switch_model_task',
            args=[model_name],
            task_id=str(uuid.uuid4())
        )
        
        logger.info(f"üîÑ Cambio de modelo async iniciado: {model_name} (Tarea: {task.id})")
        
        return {
            "task_id": task.id,
            "status": "accepted",
            "message": f"Cambio a modelo {model_name} iniciado",
            "success": True
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error iniciando cambio de modelo: {e}")
        return {"error": str(e), "success": False}

@app.get("/health/celery")
async def celery_health_check():
    """
    Health check para el sistema Celery
    """
    if not CELERY_AVAILABLE or not celery_app:
        return {
            "status": "unavailable",
            "celery_available": False,
            "message": "Celery no est√° configurado"
        }
    
    try:
        # Enviar tarea de health check
        task = celery_app.send_task('celery_worker.health_check_task')
        
        # Esperar resultado por m√°ximo 5 segundos
        try:
            result = task.get(timeout=5)
            return {
                "status": "healthy",
                "celery_available": True,
                "worker_status": result,
                "message": "Sistema Celery funcionando correctamente"
            }
        except Exception as timeout_error:
            return {
                "status": "timeout",
                "celery_available": True,
                "message": "Worker no responde (puede estar ocupado)",
                "error": str(timeout_error)
            }
            
    except Exception as e:
        logger.error(f"‚ùå Error en health check de Celery: {e}")
        return {
            "status": "error",
            "celery_available": CELERY_AVAILABLE,
            "message": "Error conectando con Celery",
            "error": str(e)
        }

async def fallback_to_sync_chat(request: AsyncChatRequest):
    """
    Fallback al m√©todo sincr√≥nico cuando Celery no est√° disponible
    """
    logger.warning("üîÑ Usando fallback sincr√≥nico para chat")
    
    try:
        # Simular el comportamiento asincr√≥nico pero ejecutar sincr√≥nicamente
        pregunta = Pregunta(
            texto=request.texto,
            userId=request.userId,
            chatToken=request.chatToken,
            modelo=request.modelo
        )
        
        # Usar el endpoint existente
        result = await preguntar_basic(pregunta)
        
        # Simular respuesta asincr√≥nica
        task_id = str(uuid.uuid4())
        return AsyncChatResponse(
            task_id=task_id,
            status="completed_sync",
            message="Procesado sincr√≥nicamente (Celery no disponible)"
        )
        
    except Exception as e:
        logger.error(f"‚ùå Error en fallback sincr√≥nico: {e}")
        return AsyncChatResponse(
            task_id="error",
            status="error",
            message=f"Error en procesamiento: {str(e)}"
        )

# ===============================================
# CONFIGURACI√ìN Y STARTUP DEL SERVIDOR
# ===============================================

# Inicializaci√≥n del servidor
if __name__ == "__main__":
    import uvicorn
    
    # Agregar una ruta catch-all para manejar cualquier ruta no encontrada
    @app.get("/{full_path:path}")
    def catch_all(full_path: str):
        # Si la ruta contiene 'index.html' o termina en '/', servir el index principal
        if 'index.html' in full_path or full_path.endswith('/') or full_path == '':
            return FileResponse("../frontend/index.html")
        # De lo contrario, devolver 404
        from fastapi import HTTPException
        raise HTTPException(status_code=404, detail="File not found")
    
    print("=" * 60)
    print("üöÄ CHATBOT EDUCATIVO - SERVIDOR FASTAPI")
    print("=" * 60)
    print("üìã Configurando rutas...")
    
    # Configurar rutas
    routes_configured = setup_routes()
    
    if routes_configured:
        print("‚úÖ Rutas configuradas correctamente")
        print("üìë Rutas disponibles:")
        dashboard_count = 0
        for route in app.routes:
            if hasattr(route, 'methods') and hasattr(route, 'path'):
                methods = ', '.join(route.methods)
                print(f"  {methods}: {route.path}")
                if route.path.startswith('/dashboard'):
                    dashboard_count += 1
        
        print(f"üìä Total de rutas del dashboard registradas: {dashboard_count}")
        
        if dashboard_count == 0:
            print("‚ö†Ô∏è No se encontraron rutas del dashboard registradas")
            print("üîÑ Intentando importar dashboard manualmente...")
            try:
                import dashboard
                print("‚úÖ Dashboard importado exitosamente")
            except Exception as e:
                print(f"‚ùå Error importando dashboard: {e}")
        else:
            print("‚úÖ Dashboard endpoints loaded successfully")
    else:
        print("‚ö†Ô∏è Algunas rutas no se pudieron configurar")
    
    print("=" * 60)
    print("üîÑ El sistema de IA se inicializar√° durante el startup del servidor")
    print("‚è≥ Esto puede tomar 30-60 segundos en el primer arranque")
    print("=" * 60)
    
    # Iniciar servidor
    try:
        print("üöÄ Iniciando servidor en http://127.0.0.1:8000")
        print("=" * 60)
        uvicorn.run(app, host="0.0.0.0", port=8000, log_level="info")
    except Exception as e:
        logger.error(f"Error iniciando servidor: {e}")
        print(f"‚ùå Error iniciando servidor: {e}")