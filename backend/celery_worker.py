# ===== CELERY WORKER PARA PROCESAMIENTO ASINCR√ìNICO =====
# Archivo: celery_worker.py
# Prop√≥sito: Worker dedicado para procesamiento de IA en segundo plano

import os
import sys
import logging
import traceback
import time
from datetime import datetime
from celery import Celery, Task
from celery.utils.log import get_task_logger

# Agregar el directorio backend al path para imports
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Imports del sistema de IA
from ai_system import AISystem
from config import *

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('celery_worker.log')
    ]
)

# Logger espec√≠fico para Celery
logger = get_task_logger(__name__)

# ===== CONFIGURACI√ìN DE CELERY =====
# Crear la aplicaci√≥n Celery
celery_app = Celery('chatbot_worker')

# Configuraci√≥n de Celery
celery_app.config_from_object({
    # Broker y Backend (Redis)
    'broker_url': 'redis://localhost:6379/0',
    'result_backend': 'redis://localhost:6379/0',
    
    # Serializaci√≥n
    'task_serializer': 'json',
    'accept_content': ['json'],
    'result_serializer': 'json',
    
    # Timezone
    'timezone': 'UTC',
    'enable_utc': True,
    
    # Configuraci√≥n de workers
    'worker_prefetch_multiplier': 1,  # Procesar una tarea a la vez por worker
    'task_acks_late': True,  # Confirmar tarea solo despu√©s de completarla
    'worker_disable_rate_limits': False,
    
    # Pool configuration para Windows
    'worker_pool': 'threads',  # Usar threads en lugar de prefork para Windows
    'worker_concurrency': 2,   # 2 threads concurrentes
    
    # Timeouts
    'task_soft_time_limit': 300,  # 5 minutos soft limit
    'task_time_limit': 600,       # 10 minutos hard limit
    
    # Retry policy
    'task_default_retry_delay': 60,
    'task_max_retries': 3,
    
    # Monitoreo
    'worker_send_task_events': True,
    'task_send_sent_event': True,
})

# ===== INSTANCIA GLOBAL DEL SISTEMA IA =====
# Se inicializa cuando el worker arranca
ai_system_instance = None

def initialize_ai_system():
    """Inicializar el sistema de IA en el worker"""
    global ai_system_instance
    
    if ai_system_instance is None:
        logger.info("üöÄ Inicializando sistema de IA en worker...")
        try:
            ai_system_instance = AISystem()
            
            # Inicializar el sistema completamente
            logger.info("üìö Cargando documentos y configurando vector store...")
            ai_system_instance.initialize_system()
            logger.info(f"‚úÖ Sistema de IA inicializado correctamente")
            logger.info(f"   - Modelo actual: {ai_system_instance.current_model}")
            logger.info(f"   - Vector store: {'S√≠' if ai_system_instance.using_vector_db else 'No'}")
            logger.info(f"   - Documentos: {len(ai_system_instance.documentos)}")
            
        except Exception as e:
            logger.error(f"‚ùå Error inicializando sistema de IA: {e}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            raise
    
    return ai_system_instance

# ===== TASK BASE CLASS =====
# class CallbackTask(Task):
#     """Clase base para tareas con callbacks de progreso"""
#     
#     def on_success(self, retval, task_id, args, kwargs):
#         """Callback ejecutado cuando la tarea es exitosa"""
#         logger.info(f"‚úÖ Tarea {task_id} completada exitosamente")
#     
#     def on_failure(self, exc, task_id, args, kwargs, einfo):
#         """Callback ejecutado cuando la tarea falla"""
#         logger.error(f"‚ùå Tarea {task_id} fall√≥: {exc}")
#         logger.error(f"Traceback: {einfo}")
#     
#     def on_retry(self, exc, task_id, args, kwargs, einfo):
#         """Callback ejecutado cuando la tarea se reintenta"""
#         logger.warning(f"üîÑ Reintentando tarea {task_id}: {exc}")

# ===== TAREAS ASINCR√ìNICAS =====

@celery_app.task(bind=True)
def process_chat_task(self, user_input, model_name=None, conversation_id=None):
    """
    Tarea asincr√≥nica para procesar consultas de chat
    
    Args:
        user_input (str): Consulta del usuario
        model_name (str, optional): Modelo a usar
        conversation_id (str, optional): ID de conversaci√≥n
    
    Returns:
        dict: Resultado del procesamiento
    """
    task_id = self.request.id
    start_time = time.time()
    current_time = datetime.utcnow().strftime('%H:%M:%S.%f')[:-3]
    
    logger.info(f"üîÑ Iniciando tarea {task_id}")
    logger.info(f"   - üïí Hora inicio: {current_time}")
    logger.info(f"   - Input: {user_input[:100]}...")
    logger.info(f"   - Modelo: {model_name or 'default'}")
    logger.info(f"   - Usuario: {(conversation_id or 'N/A')[:8]}...")
    
    try:
        # Actualizar estado: PROCESANDO
        self.update_state(
            state='PROCESSING',
            meta={
                'status': 'Inicializando sistema de IA...',
                'progress': 10,
                'start_time': start_time
            }
        )
        
        # Inicializar sistema de IA
        ai_system = initialize_ai_system()
        
        # Actualizar estado: CAMBIANDO MODELO (si es necesario)
        if model_name and model_name != ai_system.current_model:
            self.update_state(
                state='PROCESSING',
                meta={
                    'status': f'Cambiando a modelo {model_name}...',
                    'progress': 20,
                    'start_time': start_time
                }
            )
            
            logger.info(f"üîÑ Cambiando modelo a: {model_name}")
            ai_system.switch_model(model_name)
        
        # Actualizar estado: PROCESANDO CONSULTA
        self.update_state(
            state='PROCESSING',
            meta={
                'status': 'Procesando consulta con IA...',
                'progress': 40,
                'start_time': start_time
            }
        )
        
        # Procesar la consulta
        logger.info(f"ü§ñ Procesando consulta...")
        
        # Crear objeto pregunta compatible con process_question
        from models import Pregunta
        pregunta_obj = Pregunta(
            texto=user_input,
            userId=conversation_id or task_id,
            chatToken=conversation_id or task_id,
            history=[]  # Por ahora vac√≠o, se podr√≠a implementar historial despu√©s
        )
        
        result = ai_system.process_question(pregunta_obj)
        
        # Agregar etiqueta del modelo a la respuesta
        model_used = ai_system.current_model
        response_with_model = f"{result}\n\n[Respuesta generada con {model_used}]"
        
        end_time = time.time()
        processing_time = end_time - start_time
        completion_time = datetime.utcnow().strftime('%H:%M:%S.%f')[:-3]
        
        # Resultado final
        final_result = {
            'task_id': task_id,
            'status': 'completed',
            'response': response_with_model,  # Ahora incluye la etiqueta del modelo
            'model_used': model_used,
            'processing_time': round(processing_time, 2),
            'timestamp': datetime.utcnow().isoformat(),
            'conversation_id': conversation_id or task_id,
            'metadata': {
                'input_length': len(user_input),
                'response_length': len(response_with_model),
                'vector_db_used': ai_system.using_vector_db,
                'documents_count': len(ai_system.documentos)
            }
        }
        
        logger.info(f"‚úÖ Tarea {task_id} completada en {processing_time:.2f}s")
        logger.info(f"   - üïí Hora fin: {completion_time}")
        logger.info(f"   - Modelo: {model_used}")
        logger.info(f"   - Respuesta: {len(response_with_model)} chars (con etiqueta)")
        logger.info(f"   - üìä Performance: {len(user_input)} chars input ‚Üí {len(result)} chars output (+ etiqueta)")
        
        return final_result
        
    except Exception as e:
        error_msg = f"Error procesando consulta: {str(e)}"
        logger.error(f"‚ùå Tarea {task_id} fall√≥: {error_msg}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        
        # Actualizar estado: ERROR
        self.update_state(
            state='FAILURE',
            meta={
                'status': 'Error en procesamiento',
                'error': error_msg,
                'progress': 0,
                'start_time': start_time
            }
        )
        
        # Re-lanzar excepci√≥n para que Celery la maneje
        raise

@celery_app.task(bind=True)
def switch_model_task(self, model_name):
    """
    Tarea asincr√≥nica para cambiar el modelo activo
    
    Args:
        model_name (str): Nombre del modelo a activar
        
    Returns:
        dict: Estado del cambio de modelo
    """
    task_id = self.request.id
    logger.info(f"üîÑ Cambiando modelo a: {model_name} (Tarea: {task_id})")
    
    try:
        # Inicializar sistema si no existe
        ai_system = initialize_ai_system()
        
        # Cambiar modelo
        ai_system.switch_model(model_name)
        
        result = {
            'task_id': task_id,
            'status': 'completed',
            'previous_model': ai_system.current_model,
            'new_model': model_name,
            'timestamp': datetime.utcnow().isoformat()
        }
        
        logger.info(f"‚úÖ Modelo cambiado exitosamente a: {model_name}")
        return result
        
    except Exception as e:
        error_msg = f"Error cambiando modelo: {str(e)}"
        logger.error(f"‚ùå Error en tarea {task_id}: {error_msg}")
        raise

@celery_app.task
def health_check_task():
    """
    Tarea de health check para verificar el estado del worker
    
    Returns:
        dict: Estado del sistema
    """
    try:
        # Verificar conexi√≥n a Redis
        from redis import Redis
        r = Redis(host='localhost', port=6379, db=0)
        redis_status = r.ping()
        
        # Verificar sistema de IA
        ai_system = ai_system_instance
        ai_status = ai_system is not None and ai_system.is_initialized
        
        return {
            'status': 'healthy',
            'redis_connection': redis_status,
            'ai_system_initialized': ai_status,
            'current_model': ai_system.current_model if ai_system else None,
            'timestamp': datetime.utcnow().isoformat()
        }
        
    except Exception as e:
        logger.error(f"‚ùå Health check fall√≥: {e}")
        return {
            'status': 'unhealthy',
            'error': str(e),
            'timestamp': datetime.utcnow().isoformat()
        }

# ===== MANEJO DE SE√ëALES CELERY =====
from celery.signals import worker_ready, worker_shutdown

@worker_ready.connect
def worker_ready_handler(sender, **kwargs):
    """Se ejecuta cuando el worker est√° listo"""
    logger.info("üöÄ Worker de Celery listo - inicializando sistema de IA...")
    try:
        initialize_ai_system()
        logger.info("‚úÖ Worker completamente inicializado")
    except Exception as e:
        logger.error(f"‚ùå Error inicializando worker: {e}")

@worker_shutdown.connect
def worker_shutdown_handler(sender, **kwargs):
    """Se ejecuta cuando el worker se cierra"""
    logger.info("üõë Worker de Celery cerr√°ndose...")

# ===== CONFIGURACI√ìN PARA EJECUTAR =====
if __name__ == '__main__':
    # Ejecutar worker directamente con pool de threads para Windows
    import sys
    sys.argv = ['worker', '--loglevel=info', '--pool=threads', '--concurrency=2']
    celery_app.worker_main()
