# UNAB-IA Mentor v0.4.6

![Python](https://img.shields.io/badge/Python-3.9%2B-blue.svg) ![FastAPI](https://img.shields.io/badge/FastAPI-0.109-green.svg) ![LangChain](https://img.shields.io/badge/LangChain-Integrado-purple.svg) ![Ollama](https://img.shields.io/badge/Ollama-Llama%203-orange.svg)

Asistente acad茅mico inteligente dise帽ado para apoyar a estudiantes del curso "Fundamentos de Inteligencia Artificial" de la Universidad Andr茅s Bello. El sistema utiliza un modelo de lenguaje local (LLM) a trav茅s de Ollama y t茅cnicas de Retrieval-Augmented Generation (RAG) para responder preguntas basadas en el material acad茅mico del curso.

## Tabla de Contenidos
1.  [Acerca del Proyecto](#acerca-del-proyecto)
2.  [Caracter铆sticas Principales](#caracter铆sticas-principales)
3.  [Arquitectura del Sistema](#arquitectura-del-sistema)
4.  [Stack Tecnol贸gico](#stack-tecnol贸gico)
5.  [Instalaci贸n y Puesta en Marcha](#instalaci贸n-y-puesta-en-marcha)
    * [Prerrequisitos](#prerrequisitos)
    * [Configuraci贸n del Backend](#configuraci贸n-del-backend)
    * [Configuraci贸n del Frontend](#configuraci贸n-del-frontend)
6.  [Uso del Chatbot](#uso-del-chatbot)
7.  [Estructura del Proyecto](#estructura-del-proyecto)
8.  [Futuras Mejoras](#futuras-mejoras)
9.  [Licencia](#licencia)

## Acerca del Proyecto

**UNAB-IA Mentor** nace como una herramienta de apoyo educativo para resolver dudas y facilitar el aprendizaje de los conceptos clave de la inteligencia artificial. El chatbot est谩 conectado a una base de conocimientos documental (archivos PDF del curso) y es capaz de:
* Responder preguntas espec铆ficas sobre el contenido del syllabus y material de estudio.
* Mantener el contexto de la conversaci贸n para un di谩logo fluido y natural.
* Adaptar el estilo y la profundidad de sus respuestas seg煤n la intenci贸n del usuario.

## Caracter铆sticas Principales

* ** Sistema RAG (Retrieval-Augmented Generation):** Utiliza una base de datos vectorial (ChromaDB con fallback a FAISS) para encontrar los fragmentos de texto m谩s relevantes de los documentos PDF y as铆 generar respuestas precisas y contextualizadas.
* ** LLM Local con Ollama:** Integra el modelo Llama 3 (u otros compatibles con Ollama), garantizando la privacidad y el control total sobre el motor de IA.
* ** An谩lisis de Intenci贸n y Complejidad:** El sistema analiza cada pregunta para determinar la intenci贸n del usuario (ej. definici贸n, comparaci贸n, ejemplo) y la complejidad de la respuesta requerida, seleccionando la plantilla de prompt m谩s adecuada para una respuesta de alta calidad.
* ** Autenticaci贸n y Sesiones de Usuario:** Incluye un sistema de registro e inicio de sesi贸n. Las conversaciones son guardadas y asociadas a cada usuario en una base de datos MySQL, permitiendo consultar el historial.
* **猸锔 Sistema de Feedback:** Los usuarios pueden calificar las respuestas del bot (1 a 5 estrellas) y dejar comentarios, lo que permite la recolecci贸n de datos para futuras mejoras del modelo.
* ** Sugerencias Din谩micas:** Despu茅s de cada respuesta, el bot propone preguntas de seguimiento para guiar al usuario y facilitar la exploraci贸n de temas relacionados.
* ** Frontend Interactivo:** Interfaz de chat limpia y moderna construida con HTML, CSS y JavaScript, con renderizado de Markdown para una mejor legibilidad de las respuestas.

## Arquitectura del Sistema

El proyecto sigue una arquitectura cliente-servidor desacoplada:

1.  **Frontend:** Una aplicaci贸n web est谩tica (HTML, CSS, JS) que se comunica con el backend a trav茅s de peticiones HTTP.
2.  **Backend (FastAPI):** Un servidor API que recibe las preguntas del usuario.
3.  **Capa de Orquestaci贸n (LangChain):** Gestiona la l贸gica de RAG, la selecci贸n de prompts y la interacci贸n con el LLM.
4.  **Motor de IA (Ollama):** Ejecuta el modelo de lenguaje Llama 3 de forma local.
5.  **Base de Datos Vectorial (Chroma/FAISS):** Almacena y permite la b煤squeda de los embeddings de los documentos.
6.  **Base de Datos Relacional (MySQL):** Persiste la informaci贸n de usuarios, sesiones e historial de chat.

## Stack Tecnol贸gico

* **Backend:** Python, FastAPI, LangChain, SQLAlchemy
* **Frontend:** HTML5, CSS3, JavaScript (Vanilla)
* **LLM:** Ollama (Llama 3)
* **Bases de Datos:**
    * MySQL (Datos de usuario y conversaciones)
    * ChromaDB / FAISS (Base de datos vectorial)
* **Librer铆as Clave:** `pydantic`, `passlib`, `python-dotenv`, `marked.js`, `sweetalert2`

## Instalaci贸n y Puesta en Marcha

Sigue estos pasos para ejecutar el proyecto en tu entorno local.

### Prerrequisitos

* **Python 3.9+**
* **Ollama instalado y ejecut谩ndose:** [Descargar Ollama](https://ollama.com/)
* **Modelo Llama 3:** Ejecuta `ollama pull llama3` en tu terminal.
* **Servidor MySQL** instalado y accesible.

### Configuraci贸n del Backend

1.  **Clona el repositorio:**
    ```bash
    git clone [https://github.com/tu-usuario/unab-ia-mentor.git](https://github.com/tu-usuario/unab-ia-mentor.git)
    cd unab-ia-mentor
    ```

2.  **Crea un entorno virtual y act铆valo:**
    ```bash
    python -m venv venv
    # En Windows
    venv\Scripts\activate
    # En macOS/Linux
    source venv/bin/activate
    ```

3.  **Crea el archivo `requirements.txt`** con el siguiente contenido:
    ```txt
    fastapi
    uvicorn[standard]
    sqlalchemy
    mysql-connector-python
    langchain
    langchain-community
    langchain-ollama
    pypdf
    faiss-cpu
    chromadb
    passlib[bcrypt]
    python-dotenv
    ```

4.  **Instala las dependencias:**
    ```bash
    pip install -r requirements.txt
    ```

5.  **Crea un archivo `.env`** en la ra铆z del proyecto y config煤ralo con tus credenciales de MySQL:
    ```env
    DB_USER="tu_usuario_mysql"
    DB_PASSWORD="tu_password_mysql"
    DB_HOST="127.0.0.1"
    DB_PORT="3306"
    DB_NAME="bd_chatbot"
    ```

6.  **Crea la base de datos `bd_chatbot`** en tu servidor MySQL. Las tablas se crear谩n autom谩ticamente al iniciar la aplicaci贸n por primera vez.

7.  **A帽ade tus documentos:** Coloca los archivos PDF que servir谩n como base de conocimiento en la carpeta `/pdfs/`.

8.  **Inicia el servidor:**
    ```bash
    uvicorn app:app --reload
    ```
    El backend estar谩 disponible en `http://localhost:8000`.

### Configuraci贸n del Frontend

No requiere pasos adicionales. Simplemente abre `http://localhost:8000` en tu navegador, ya que FastAPI est谩 configurado para servir el archivo `index.html` en la ruta ra铆z.

## Uso del Chatbot

1.  **Registro/Login:** La primera vez, reg铆strate con un nombre, email y contrase帽a. Luego, inicia sesi贸n.
2.  **Interfaz de Chat:** Se presentar谩 la ventana principal del chat.
3.  **Realiza una pregunta:** Escribe tu pregunta en el campo de texto y presiona "Enviar" o la tecla Enter.
4.  **Usa las sugerencias:** Haz clic en los botones de sugerencia para explorar temas relacionados.
5.  **Califica las respuestas:** Usa el sistema de estrellas para dar tu feedback sobre la utilidad de cada respuesta.
6.  **Gestiona tus conversaciones:** Usa los botones "Nueva conversaci贸n" para empezar de cero o "Historial" para ver y cargar chats anteriores.

## Estructura del Proyecto
